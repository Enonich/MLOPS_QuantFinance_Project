{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12ddd9d8-da8b-4f4b-b41a-3ab91fa13304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from feature_engineering import calculate_bollinger_bands, calculate_daily_return, calculate_macd, calculate_sma, average_true_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33a8ec68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MLFLOW_TRACKING_URI=sqlite:///mlruns.db\n"
     ]
    }
   ],
   "source": [
    "# setting up mlflow tracking\n",
    "import mlflow\n",
    "\n",
    "# mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "# mlflow.set_experiment(\"stock-pred-exp\")\n",
    "\n",
    "%env MLFLOW_TRACKING_URI = sqlite:///mlruns.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e26705ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/04 20:04:20 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2024/02/04 20:04:20 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\n",
      "INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "INFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "INFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.create_experiment(\n",
    "   name='stock_pred_exp',\n",
    "   artifact_location='testing_mlflow_artifacts',\n",
    "   tags={'env': \"dev\", \"version\": \"1.0.0\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd12b803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/04 23:31:30 INFO mlflow.tracking.fluent: Experiment with name 'stock_pred_exp' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'when running the mlflow and logging the artifacts, \\nwe can use this code to log to the specific experiment:\\n\\nwith mlflow.start_run(run_name=\"blah_blah\", experiment_id = experiment.experiment_id) as run:\\n\\n\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(experiment_name='stock_pred_exp')\n",
    "# OR\n",
    "\n",
    "\"\"\"when running the mlflow and logging the artifacts, \n",
    "we can use this code to log to the specific experiment:\n",
    "\n",
    "with mlflow.start_run(run_name=\"blah_blah\", experiment_id = experiment.experiment_id) as run:\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "065d972e-9155-43ab-b731-e7b997fbc0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    df = pd.read_csv(filename, index_col='Datetime')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c4da7af-26b1-4921-af40-58de10158fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_dataframe('../Data/EURUSD=X_5m.csv')\n",
    "test_data  = read_dataframe('../Data/AAPL_5m.csv')\n",
    "\n",
    "# Defines Dependent and Independent Variables\n",
    "y_train = train_data[['Adj Close']]\n",
    "y_test = test_data[['Adj Close']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb5b069",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "541272ee-7ebf-4870-9539-032e340ff395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ATR</th>\n",
       "      <th>MACD_Line</th>\n",
       "      <th>Signal_Line</th>\n",
       "      <th>MACD_Histogram</th>\n",
       "      <th>Daily Return</th>\n",
       "      <th>Upper Band</th>\n",
       "      <th>Lower Band</th>\n",
       "      <th>Simple Moving Avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-03-14 00:00:00+00:00</th>\n",
       "      <td>1.072731</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.072041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-14 00:05:00+00:00</th>\n",
       "      <td>1.071926</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.053575</td>\n",
       "      <td>1.072566</td>\n",
       "      <td>1.070942</td>\n",
       "      <td>1.071754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-14 00:10:00+00:00</th>\n",
       "      <td>1.071582</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>0.032154</td>\n",
       "      <td>1.072351</td>\n",
       "      <td>1.071195</td>\n",
       "      <td>1.071773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-14 00:15:00+00:00</th>\n",
       "      <td>1.071697</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>0.010722</td>\n",
       "      <td>1.072308</td>\n",
       "      <td>1.071315</td>\n",
       "      <td>1.071811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-14 00:20:00+00:00</th>\n",
       "      <td>1.071926</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.021441</td>\n",
       "      <td>1.072409</td>\n",
       "      <td>1.071351</td>\n",
       "      <td>1.071880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-05 16:05:00+01:00</th>\n",
       "      <td>1.071467</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.010703</td>\n",
       "      <td>1.073630</td>\n",
       "      <td>1.067999</td>\n",
       "      <td>1.070815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-05 16:10:00+01:00</th>\n",
       "      <td>1.071237</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>0.010704</td>\n",
       "      <td>1.073585</td>\n",
       "      <td>1.068330</td>\n",
       "      <td>1.070958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-05 16:15:00+01:00</th>\n",
       "      <td>1.071467</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>-0.010703</td>\n",
       "      <td>1.073516</td>\n",
       "      <td>1.068651</td>\n",
       "      <td>1.071084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-05 16:20:00+01:00</th>\n",
       "      <td>1.071467</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>0.021419</td>\n",
       "      <td>1.073396</td>\n",
       "      <td>1.069057</td>\n",
       "      <td>1.071227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-05 16:25:00+01:00</th>\n",
       "      <td>1.071582</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>-0.000090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.073313</td>\n",
       "      <td>1.069370</td>\n",
       "      <td>1.071341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16941 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Open  Volume       ATR  MACD_Line  Signal_Line   \n",
       "Datetime                                                                        \n",
       "2023-03-14 00:00:00+00:00  1.072731       0       NaN   0.000000     0.000000  \\\n",
       "2023-03-14 00:05:00+00:00  1.071926       0       NaN  -0.000046    -0.000009   \n",
       "2023-03-14 00:10:00+00:00  1.071582       0       NaN  -0.000054    -0.000018   \n",
       "2023-03-14 00:15:00+00:00  1.071697       0       NaN  -0.000050    -0.000024   \n",
       "2023-03-14 00:20:00+00:00  1.071926       0       NaN  -0.000028    -0.000025   \n",
       "...                             ...     ...       ...        ...          ...   \n",
       "2023-06-05 16:05:00+01:00  1.071467       0  0.000590   0.000662     0.000701   \n",
       "2023-06-05 16:10:00+01:00  1.071237       0  0.000394   0.000625     0.000686   \n",
       "2023-06-05 16:15:00+01:00  1.071467       0  0.000361   0.000579     0.000665   \n",
       "2023-06-05 16:20:00+01:00  1.071467       0  0.000361   0.000556     0.000643   \n",
       "2023-06-05 16:25:00+01:00  1.071582       0  0.000336   0.000531     0.000620   \n",
       "\n",
       "                           MACD_Histogram  Daily Return  Upper Band   \n",
       "Datetime                                                              \n",
       "2023-03-14 00:00:00+00:00        0.000000           NaN         NaN  \\\n",
       "2023-03-14 00:05:00+00:00       -0.000037     -0.053575    1.072566   \n",
       "2023-03-14 00:10:00+00:00       -0.000036      0.032154    1.072351   \n",
       "2023-03-14 00:15:00+00:00       -0.000026      0.010722    1.072308   \n",
       "2023-03-14 00:20:00+00:00       -0.000003      0.021441    1.072409   \n",
       "...                                   ...           ...         ...   \n",
       "2023-06-05 16:05:00+01:00       -0.000039     -0.010703    1.073630   \n",
       "2023-06-05 16:10:00+01:00       -0.000061      0.010704    1.073585   \n",
       "2023-06-05 16:15:00+01:00       -0.000085     -0.010703    1.073516   \n",
       "2023-06-05 16:20:00+01:00       -0.000087      0.021419    1.073396   \n",
       "2023-06-05 16:25:00+01:00       -0.000090      0.000000    1.073313   \n",
       "\n",
       "                           Lower Band  Simple Moving Avg  \n",
       "Datetime                                                  \n",
       "2023-03-14 00:00:00+00:00         NaN           1.072041  \n",
       "2023-03-14 00:05:00+00:00    1.070942           1.071754  \n",
       "2023-03-14 00:10:00+00:00    1.071195           1.071773  \n",
       "2023-03-14 00:15:00+00:00    1.071315           1.071811  \n",
       "2023-03-14 00:20:00+00:00    1.071351           1.071880  \n",
       "...                               ...                ...  \n",
       "2023-06-05 16:05:00+01:00    1.067999           1.070815  \n",
       "2023-06-05 16:10:00+01:00    1.068330           1.070958  \n",
       "2023-06-05 16:15:00+01:00    1.068651           1.071084  \n",
       "2023-06-05 16:20:00+01:00    1.069057           1.071227  \n",
       "2023-06-05 16:25:00+01:00    1.069370           1.071341  \n",
       "\n",
       "[16941 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FEATURE ENGINEERING ON TRAIN AND TEST DATA\n",
    "#Feature Engineering on train_set\n",
    "atr_data = average_true_range(train_data)\n",
    "macd_data = calculate_macd(train_data)\n",
    "dr_data = calculate_daily_return(train_data)\n",
    "bb_data = calculate_bollinger_bands(train_data)\n",
    "sma_data = calculate_sma(train_data)\n",
    "train_sets = sma_data\n",
    "\n",
    "\n",
    "#Feature Engineering on train_set\n",
    "atr_data = average_true_range(test_data)\n",
    "macd_data = calculate_macd(test_data)\n",
    "dr_data = calculate_daily_return(test_data)\n",
    "bb_data = calculate_bollinger_bands(test_data)\n",
    "sma_data = calculate_sma(test_data)\n",
    "test_sets = sma_data\n",
    "\n",
    "train_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2aaaf7ac-1976-4ec9-a88f-c4249f30f9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPROCESSING\n",
    "train_dataset = pd.merge(train_sets, y_train, on='Datetime')\n",
    "train_dataset = train_dataset.dropna()\n",
    "\n",
    "test_dataset = pd.merge(test_sets, y_test, on='Datetime')\n",
    "test_dataset = test_dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6769469b-2e30-4908-a000-4145dd2f2961",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_dataset.drop(['Open', 'Adj Close', 'Volume'], axis=1)\n",
    "y_train = train_dataset[['Adj Close']]\n",
    "\n",
    "x_test = test_dataset.drop(['Open', 'Adj Close', 'Volume'], axis=1)\n",
    "y_test = test_dataset[['Adj Close']]\n",
    "\n",
    "# Dropping The Last Row of the x_train and the first row of the y_train  \n",
    "x_train = x_train.drop(x_train.index[-1])\n",
    "y_train = y_train.drop(y_train.index[0])\n",
    "\n",
    "# Dropping The Last Row of the x_test and the first row of the y_test\n",
    "x_test = x_test.drop(x_test.index[-1])\n",
    "y_test = y_test.drop(y_test.index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83c3a03-e859-47df-8cb0-9832b2c211bb",
   "metadata": {},
   "source": [
    "### MODEL ARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e61247f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    \n",
    "    mlflow.sklearn.autolog()\n",
    "    \n",
    "    # logging parameters\n",
    "    mlflow.log_param(\"train-data-path\", \"../Data/EURUSD=X_5m.csv\")\n",
    "    mlflow.log_param(\"test-data-path\", \"../Data/AAPL_5m.csv\")\n",
    "    mlflow.set_tag(\"developer\", \"Enoch\")\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    degree = 1\n",
    "    linear_model = make_pipeline( StandardScaler(), model)\n",
    "    linear_model.fit(x_train, y_train)\n",
    "    \n",
    "    mlflow.set_tag('model', 'LinearRegressor')\n",
    "    # MAKE PREDICTIONS AND CHECK THE VARIANCE AND BIAS VALUES\n",
    "    train_pred = linear_model.predict(x_train)\n",
    "    test_pred = linear_model.predict(x_test)\n",
    "    \n",
    "    train_mse = mean_squared_error(y_train, train_pred, squared=False)\n",
    "    test_mse = mean_squared_error(y_test, test_pred, squared=False)\n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    test_r2 = r2_score(y_test, test_pred)\n",
    "    \n",
    "    mlflow.log_metric(\"rmse\", test_mse)\n",
    "    mlflow.log_metric(\"r2\", test_r2)\n",
    "    \n",
    "    #mlflow.log_artifact(local_path=\"../models/Linear_Reg.pkl\", artifact_path=\"models_pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b82cdac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse: 0.00035554292608154454\n",
      "train r2: 0.9991575178139349\n",
      "test mse: 0.30991165941859333\n",
      "test r2: 0.9982911037294748\n"
     ]
    }
   ],
   "source": [
    "print('train mse:', train_mse)\n",
    "print('train r2:', train_r2)\n",
    "print('test mse:', test_mse)\n",
    "print('test r2:', test_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494f8014",
   "metadata": {},
   "source": [
    "#### Ridge Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36a0b166-0a38-4567-9cf1-2e6f521144fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    \n",
    "    mlflow.sklearn.autolog()\n",
    "    \n",
    "    # logging parameters\n",
    "    mlflow.log_param(\"polynomial degree\", 1)\n",
    "    mlflow.log_param(\"alpha\", 0.1)\n",
    "    \n",
    "    degree = 1\n",
    "    alpha = 0.1  # Regularization strength\n",
    "    ridge_model = make_pipeline(PolynomialFeatures(degree=degree), StandardScaler(), Ridge(alpha=alpha))\n",
    "    ridge_model.fit(x_train, y_train)\n",
    "    \n",
    "    # MAKE PREDICTIONS AND CHECK THE VARIANCE AND BIAS VALUES\n",
    "    train_pred = ridge_model.predict(x_train)\n",
    "    test_pred = ridge_model.predict(x_test)\n",
    "    mlflow.set_tag('model', 'RidgeRegressor')\n",
    "    \n",
    "    train_mse = mean_squared_error(y_train, train_pred, squared=False)\n",
    "    test_mse = mean_squared_error(y_test, test_pred, squared=False)\n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    test_r2 = r2_score(y_test, test_pred)\n",
    "    \n",
    "    mlflow.log_metric(\"rmse\", test_mse)\n",
    "    mlflow.log_metric(\"r2\", test_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a2031ce-376b-4815-b366-0759b237c160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse: 0.0003555427720491671\n",
      "train r2: 0.9991575185439143\n",
      "test mse: 0.30955395242571454\n",
      "test r2: 0.9982950463456918\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('train mse:', train_mse)\n",
    "print('train r2:', train_r2)\n",
    "print('test mse:', test_mse)\n",
    "print('test r2:', test_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4192969e",
   "metadata": {},
   "source": [
    "### Lasso Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a340b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    \n",
    "    mlflow.sklearn.autolog()\n",
    "    \n",
    "    # logging parameters\n",
    "    #mlflow.log_param(\"train-data-path\", \"../Data/EURUSD=X_5m.csv\")\n",
    "    #mlflow.log_param(\"test-data-path\", \"../Data/AAPL_5m.csv\")\n",
    "    \n",
    "    \n",
    "    model = LinearRegression()\n",
    "    degree = 1\n",
    "    alpha = 0.00001  # Regularization strength\n",
    "    lasso_model = make_pipeline(PolynomialFeatures(degree=degree), StandardScaler(), Lasso(alpha=alpha))\n",
    "    lasso_model.fit(x_train, y_train)\n",
    "    \n",
    "    mlflow.set_tag('model', 'LassoRegressor')\n",
    "    # MAKE PREDICTIONS AND CHECK THE VARIANCE AND BIAS VALUES\n",
    "    train_pred = lasso_model.predict(x_train)\n",
    "    test_pred = lasso_model.predict(x_test)\n",
    "    \n",
    "    train_mse = mean_squared_error(y_train, train_pred, squared=False)\n",
    "    test_mse = mean_squared_error(y_test, test_pred, squared=False)\n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    test_r2 = r2_score(y_test, test_pred)\n",
    "    \n",
    "    mlflow.log_metric(\"rmse\", test_mse)\n",
    "    mlflow.log_metric(\"r2\", test_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "749ec083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse: 0.0003560888486147838\n",
      "train r2: 0.999154928629463\n",
      "test mse: 0.35106833861197767\n",
      "test r2: 0.9978070779264776\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('train mse:', train_mse)\n",
    "print('train r2:', train_r2)\n",
    "print('test mse:', test_mse)\n",
    "print('test r2:', test_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde4b24d",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent Regressor with Ridge Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0651edf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AIDOO K. ENOCH\\.conda\\envs\\model_orch\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    mlflow.sklearn.autolog()\n",
    "     # logging parameters\n",
    "    #mlflow.log_param(\"train-data-path\", \"../Data/EURUSD=X_5m.csv\")\n",
    "    #mlflow.log_param(\"test-data-path\", \"../Data/AAPL_5m.csv\")\n",
    "\n",
    "    degree = 1      # 1\n",
    "    alpha = 0.002  # Regularization strength 0.0001\n",
    "    max_iter = 115  # 120\n",
    "\n",
    "    SGD_model = make_pipeline(PolynomialFeatures(degree=degree), StandardScaler(), SGDRegressor(alpha=alpha, max_iter=max_iter))\n",
    "    SGD_model.fit(x_train, y_train)\n",
    "    mlflow.set_tag('model', 'SGDRegressor')\n",
    "    \n",
    "    \n",
    "    # MAKE PREDICTIONS AND CHECK THE VARIANCE AND BIAS VALUES\n",
    "    train_pred = SGD_model.predict(x_train)\n",
    "    test_pred = SGD_model.predict(x_test)\n",
    "    \n",
    "    train_mse = mean_squared_error(y_train, train_pred, squared=False)\n",
    "    test_mse = mean_squared_error(y_test, test_pred, squared=False)\n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    test_r2 = r2_score(y_test, test_pred)\n",
    "    \n",
    "    mlflow.log_metric(\"rmse\", test_mse)\n",
    "    mlflow.log_metric(\"r2\", test_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9150fc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse: 0.00035738209390664787\n",
      "train r2: 0.9991487792139596\n",
      "test mse: 0.31108878493922765\n",
      "test r2: 0.9982780974058042\n"
     ]
    }
   ],
   "source": [
    "print('train mse:', train_mse)\n",
    "print('train r2:', train_r2)\n",
    "print('test mse:', test_mse)\n",
    "print('test r2:', test_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d8a4a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "\n",
    "train = xgb.DMatrix(x_train, label=y_train)\n",
    "valid = xgb.DMatrix(x_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f46f360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\", \"xgboost\")\n",
    "        mlflow.log_params(params)\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=1000,\n",
    "            evals=[(valid, 'validation')],\n",
    "            early_stopping_rounds=50\n",
    "        )\n",
    "        y_pred = booster.predict(valid)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    return {'loss': rmse, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "864d90ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:59:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\objective\\regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation-rmse:165.64289                         \n",
      "[1]\tvalidation-rmse:165.49477                         \n",
      "[2]\tvalidation-rmse:165.41107                         \n",
      "[3]\tvalidation-rmse:165.36202                         \n",
      "[4]\tvalidation-rmse:165.33458                         \n",
      "[5]\tvalidation-rmse:165.31803                         \n",
      "[6]\tvalidation-rmse:165.30892                         \n",
      "[7]\tvalidation-rmse:165.30312                         \n",
      "[8]\tvalidation-rmse:165.30036                         \n",
      "[9]\tvalidation-rmse:165.29805                         \n",
      "[10]\tvalidation-rmse:165.29753                        \n",
      "[11]\tvalidation-rmse:165.29652                        \n",
      "[12]\tvalidation-rmse:165.29631                        \n",
      "[13]\tvalidation-rmse:165.29606                        \n",
      "[14]\tvalidation-rmse:165.29596                        \n",
      "[15]\tvalidation-rmse:165.29591                        \n",
      "[16]\tvalidation-rmse:165.29576                        \n",
      "[17]\tvalidation-rmse:165.29572                        \n",
      "[18]\tvalidation-rmse:165.29572                        \n",
      "[19]\tvalidation-rmse:165.29563                        \n",
      "[20]\tvalidation-rmse:165.29553                        \n",
      "[21]\tvalidation-rmse:165.29553                        \n",
      "[22]\tvalidation-rmse:165.29553                        \n",
      "[23]\tvalidation-rmse:165.29553                        \n",
      "[24]\tvalidation-rmse:165.29552                        \n",
      "[25]\tvalidation-rmse:165.29552                        \n",
      "[26]\tvalidation-rmse:165.29546                        \n",
      "[27]\tvalidation-rmse:165.29545                        \n",
      "[28]\tvalidation-rmse:165.29544                        \n",
      "[29]\tvalidation-rmse:165.29544                        \n",
      "[30]\tvalidation-rmse:165.29544                        \n",
      "[31]\tvalidation-rmse:165.29544                        \n",
      "[32]\tvalidation-rmse:165.29544                        \n",
      "[33]\tvalidation-rmse:165.29544                        \n",
      "[34]\tvalidation-rmse:165.29544                        \n",
      "[35]\tvalidation-rmse:165.29544                        \n",
      "[36]\tvalidation-rmse:165.29544                        \n",
      "[37]\tvalidation-rmse:165.29544                        \n",
      "[38]\tvalidation-rmse:165.29544                        \n",
      "[39]\tvalidation-rmse:165.29544                        \n",
      "[40]\tvalidation-rmse:165.29544                        \n",
      "[41]\tvalidation-rmse:165.29544                        \n",
      "[42]\tvalidation-rmse:165.29544                        \n",
      "[43]\tvalidation-rmse:165.29544                        \n",
      "[44]\tvalidation-rmse:165.29544                        \n",
      "[45]\tvalidation-rmse:165.29544                        \n",
      "[46]\tvalidation-rmse:165.29544                        \n",
      "[47]\tvalidation-rmse:165.29544                        \n",
      "[48]\tvalidation-rmse:165.29544                        \n",
      "[49]\tvalidation-rmse:165.29544                        \n",
      "[50]\tvalidation-rmse:165.29544                        \n",
      "[51]\tvalidation-rmse:165.29544                        \n",
      "[52]\tvalidation-rmse:165.29544                        \n",
      "[53]\tvalidation-rmse:165.29544                        \n",
      "[54]\tvalidation-rmse:165.29544                        \n",
      "[55]\tvalidation-rmse:165.29544                        \n",
      "[56]\tvalidation-rmse:165.29544                        \n",
      "[57]\tvalidation-rmse:165.29544                        \n",
      "[58]\tvalidation-rmse:165.29544                        \n",
      "[59]\tvalidation-rmse:165.29544                        \n",
      "[60]\tvalidation-rmse:165.29544                        \n",
      "[61]\tvalidation-rmse:165.29544                        \n",
      "[62]\tvalidation-rmse:165.29544                        \n",
      "[63]\tvalidation-rmse:165.29544                        \n",
      "[64]\tvalidation-rmse:165.29544                        \n",
      "[65]\tvalidation-rmse:165.29544                        \n",
      "[66]\tvalidation-rmse:165.29544                        \n",
      "[67]\tvalidation-rmse:165.29544                        \n",
      "[68]\tvalidation-rmse:165.29544                        \n",
      "[69]\tvalidation-rmse:165.29544                        \n",
      "[70]\tvalidation-rmse:165.29544                        \n",
      "[71]\tvalidation-rmse:165.29544                        \n",
      "[72]\tvalidation-rmse:165.29544                        \n",
      "[73]\tvalidation-rmse:165.29544                        \n",
      "[74]\tvalidation-rmse:165.29544                        \n",
      "[75]\tvalidation-rmse:165.29544                        \n",
      "[76]\tvalidation-rmse:165.29544                        \n",
      "[77]\tvalidation-rmse:165.29544                        \n",
      "[78]\tvalidation-rmse:165.29544                        \n",
      "[16:59:15] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\objective\\regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation-rmse:165.80465                                                   \n",
      "[1]\tvalidation-rmse:165.72371                                                   \n",
      "[2]\tvalidation-rmse:165.65590                                                   \n",
      "[3]\tvalidation-rmse:165.59900                                                   \n",
      "[4]\tvalidation-rmse:165.55138                                                   \n",
      "[5]\tvalidation-rmse:165.51074                                                   \n",
      "[6]\tvalidation-rmse:165.47712                                                   \n",
      "[7]\tvalidation-rmse:165.44832                                                   \n",
      "[8]\tvalidation-rmse:165.42427                                                   \n",
      "[9]\tvalidation-rmse:165.40429                                                   \n",
      "[10]\tvalidation-rmse:165.38709                                                  \n",
      "[11]\tvalidation-rmse:165.37310                                                  \n",
      "[12]\tvalidation-rmse:165.36121                                                  \n",
      "[13]\tvalidation-rmse:165.35083                                                  \n",
      "[14]\tvalidation-rmse:165.34243                                                  \n",
      "[15]\tvalidation-rmse:165.33531                                                  \n",
      "[16]\tvalidation-rmse:165.32941                                                  \n",
      "[17]\tvalidation-rmse:165.32409                                                  \n",
      "[18]\tvalidation-rmse:165.31958                                                  \n",
      "[19]\tvalidation-rmse:165.31610                                                  \n",
      "[20]\tvalidation-rmse:165.31304                                                  \n",
      "[21]\tvalidation-rmse:165.31033                                                  \n",
      "[22]\tvalidation-rmse:165.30828                                                  \n",
      "[23]\tvalidation-rmse:165.30624                                                  \n",
      "[24]\tvalidation-rmse:165.30472                                                  \n",
      "[25]\tvalidation-rmse:165.30347                                                  \n",
      "[26]\tvalidation-rmse:165.30240                                                  \n",
      "[27]\tvalidation-rmse:165.30184                                                  \n",
      "[28]\tvalidation-rmse:165.30136                                                  \n",
      "[29]\tvalidation-rmse:165.30103                                                  \n",
      "[30]\tvalidation-rmse:165.30083                                                  \n",
      "[31]\tvalidation-rmse:165.30054                                                  \n",
      "[32]\tvalidation-rmse:165.29994                                                  \n",
      "[33]\tvalidation-rmse:165.29971                                                  \n",
      "[34]\tvalidation-rmse:165.29952                                                  \n",
      "[35]\tvalidation-rmse:165.29925                                                  \n",
      "[36]\tvalidation-rmse:165.29911                                                  \n",
      "[37]\tvalidation-rmse:165.29888                                                  \n",
      "[38]\tvalidation-rmse:165.29872                                                  \n",
      "[39]\tvalidation-rmse:165.29863                                                  \n",
      "[40]\tvalidation-rmse:165.29858                                                  \n",
      "[41]\tvalidation-rmse:165.29846                                                  \n",
      "[42]\tvalidation-rmse:165.29846                                                  \n",
      "[43]\tvalidation-rmse:165.29835                                                  \n",
      "[44]\tvalidation-rmse:165.29824                                                  \n",
      "[45]\tvalidation-rmse:165.29819                                                  \n",
      "[46]\tvalidation-rmse:165.29816                                                  \n",
      "[47]\tvalidation-rmse:165.29811                                                  \n",
      "[48]\tvalidation-rmse:165.29807                                                  \n",
      "[49]\tvalidation-rmse:165.29802                                                  \n",
      "[50]\tvalidation-rmse:165.29800                                                  \n",
      "[51]\tvalidation-rmse:165.29796                                                  \n",
      "[52]\tvalidation-rmse:165.29794                                                  \n",
      "[53]\tvalidation-rmse:165.29790                                                  \n",
      "[54]\tvalidation-rmse:165.29786                                                  \n",
      "[55]\tvalidation-rmse:165.29784                                                  \n",
      "[56]\tvalidation-rmse:165.29784                                                  \n",
      "[57]\tvalidation-rmse:165.29780                                                  \n",
      "[58]\tvalidation-rmse:165.29780                                                  \n",
      "[59]\tvalidation-rmse:165.29777                                                  \n",
      "[60]\tvalidation-rmse:165.29777                                                  \n",
      "[61]\tvalidation-rmse:165.29776                                                  \n",
      "[62]\tvalidation-rmse:165.29771                                                  \n",
      "[63]\tvalidation-rmse:165.29768                                                  \n",
      "[64]\tvalidation-rmse:165.29768                                                  \n",
      "[65]\tvalidation-rmse:165.29766                                                  \n",
      "[66]\tvalidation-rmse:165.29766                                                  \n",
      "[67]\tvalidation-rmse:165.29765                                                  \n",
      "[68]\tvalidation-rmse:165.29763                                                  \n",
      "[69]\tvalidation-rmse:165.29762                                                  \n",
      "[70]\tvalidation-rmse:165.29760                                                  \n",
      "[71]\tvalidation-rmse:165.29759                                                  \n",
      "[72]\tvalidation-rmse:165.29759                                                  \n",
      "[73]\tvalidation-rmse:165.29758                                                  \n",
      "[74]\tvalidation-rmse:165.29758                                                  \n",
      "[75]\tvalidation-rmse:165.29757                                                  \n",
      "[76]\tvalidation-rmse:165.29756                                                  \n",
      "[77]\tvalidation-rmse:165.29755                                                  \n",
      "[78]\tvalidation-rmse:165.29755                                                  \n",
      "[79]\tvalidation-rmse:165.29753                                                  \n",
      "[80]\tvalidation-rmse:165.29753                                                  \n",
      "[81]\tvalidation-rmse:165.29753                                                  \n",
      "[82]\tvalidation-rmse:165.29751                                                  \n",
      "[83]\tvalidation-rmse:165.29751                                                  \n",
      "[84]\tvalidation-rmse:165.29751                                                  \n",
      "[85]\tvalidation-rmse:165.29751                                                  \n",
      "[86]\tvalidation-rmse:165.29749                                                  \n",
      "[87]\tvalidation-rmse:165.29749                                                  \n",
      "[88]\tvalidation-rmse:165.29749                                                  \n",
      "[89]\tvalidation-rmse:165.29749                                                  \n",
      "[90]\tvalidation-rmse:165.29749                                                  \n",
      "[91]\tvalidation-rmse:165.29749                                                  \n",
      "[92]\tvalidation-rmse:165.29749                                                  \n",
      "[93]\tvalidation-rmse:165.29749                                                  \n",
      "[94]\tvalidation-rmse:165.29749                                                  \n",
      "[95]\tvalidation-rmse:165.29749                                                  \n",
      "[96]\tvalidation-rmse:165.29749                                                  \n",
      "[97]\tvalidation-rmse:165.29749                                                  \n",
      "[98]\tvalidation-rmse:165.29749                                                  \n",
      "[99]\tvalidation-rmse:165.29749                                                  \n",
      "[100]\tvalidation-rmse:165.29749                                                 \n",
      "[101]\tvalidation-rmse:165.29749                                                 \n",
      "[102]\tvalidation-rmse:165.29749                                                 \n",
      "[103]\tvalidation-rmse:165.29749                                                 \n",
      "[104]\tvalidation-rmse:165.29749                                                 \n",
      "[105]\tvalidation-rmse:165.29749                                                 \n",
      "[106]\tvalidation-rmse:165.29749                                                 \n",
      "[107]\tvalidation-rmse:165.29749                                                 \n",
      "[108]\tvalidation-rmse:165.29749                                                 \n",
      "[109]\tvalidation-rmse:165.29749                                                 \n",
      "[110]\tvalidation-rmse:165.29749                                                 \n",
      "[111]\tvalidation-rmse:165.29749                                                 \n",
      "[112]\tvalidation-rmse:165.29749                                                 \n",
      "[113]\tvalidation-rmse:165.29749                                                 \n",
      "[114]\tvalidation-rmse:165.29749                                                 \n",
      "[115]\tvalidation-rmse:165.29749                                                 \n",
      "[116]\tvalidation-rmse:165.29749                                                 \n",
      "[117]\tvalidation-rmse:165.29749                                                 \n",
      "[118]\tvalidation-rmse:165.29749                                                 \n",
      "[119]\tvalidation-rmse:165.29749                                                 \n",
      "[120]\tvalidation-rmse:165.29749                                                 \n",
      "[121]\tvalidation-rmse:165.29749                                                 \n",
      "[122]\tvalidation-rmse:165.29749                                                 \n",
      "[123]\tvalidation-rmse:165.29749                                                 \n",
      "[124]\tvalidation-rmse:165.29749                                                 \n",
      "[125]\tvalidation-rmse:165.29749                                                 \n",
      "[126]\tvalidation-rmse:165.29749                                                 \n",
      "[127]\tvalidation-rmse:165.29749                                                 \n",
      "[128]\tvalidation-rmse:165.29749                                                 \n",
      "[129]\tvalidation-rmse:165.29749                                                 \n",
      "[130]\tvalidation-rmse:165.29749                                                 \n",
      "[131]\tvalidation-rmse:165.29749                                                 \n",
      "[132]\tvalidation-rmse:165.29749                                                 \n",
      "[133]\tvalidation-rmse:165.29749                                                 \n",
      "[134]\tvalidation-rmse:165.29749                                                 \n",
      "[135]\tvalidation-rmse:165.29749                                                 \n",
      "[136]\tvalidation-rmse:165.29749                                                 \n",
      "[137]\tvalidation-rmse:165.29749                                                 \n",
      "[16:59:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\objective\\regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation-rmse:165.49148                                                   \n",
      "[1]\tvalidation-rmse:165.36063                                                   \n",
      "[2]\tvalidation-rmse:165.31650                                                   \n",
      "[3]\tvalidation-rmse:165.30283                                                   \n",
      "[4]\tvalidation-rmse:165.29672                                                   \n",
      "[5]\tvalidation-rmse:165.29540                                                   \n",
      "[6]\tvalidation-rmse:165.29505                                                   \n",
      "[7]\tvalidation-rmse:165.29423                                                   \n",
      "[8]\tvalidation-rmse:165.29410                                                   \n",
      "[9]\tvalidation-rmse:165.29410                                                   \n",
      "[10]\tvalidation-rmse:165.29401                                                  \n",
      "[11]\tvalidation-rmse:165.29396                                                  \n",
      "[12]\tvalidation-rmse:165.29396                                                  \n",
      "[13]\tvalidation-rmse:165.29393                                                  \n",
      "[14]\tvalidation-rmse:165.29392                                                  \n",
      "[15]\tvalidation-rmse:165.29392                                                  \n",
      "[16]\tvalidation-rmse:165.29392                                                  \n",
      "[17]\tvalidation-rmse:165.29392                                                  \n",
      "[18]\tvalidation-rmse:165.29392                                                  \n",
      "[19]\tvalidation-rmse:165.29392                                                  \n",
      "[20]\tvalidation-rmse:165.29392                                                  \n",
      "[21]\tvalidation-rmse:165.29392                                                  \n",
      "[22]\tvalidation-rmse:165.29392                                                  \n",
      "[23]\tvalidation-rmse:165.29392                                                  \n",
      "[24]\tvalidation-rmse:165.29392                                                  \n",
      "[25]\tvalidation-rmse:165.29392                                                  \n",
      "[26]\tvalidation-rmse:165.29392                                                  \n",
      "[27]\tvalidation-rmse:165.29392                                                  \n",
      "[28]\tvalidation-rmse:165.29392                                                  \n",
      "[29]\tvalidation-rmse:165.29392                                                  \n",
      "[30]\tvalidation-rmse:165.29392                                                  \n",
      "[31]\tvalidation-rmse:165.29392                                                  \n",
      "[32]\tvalidation-rmse:165.29392                                                  \n",
      "[33]\tvalidation-rmse:165.29392                                                  \n",
      "[34]\tvalidation-rmse:165.29392                                                  \n",
      "[35]\tvalidation-rmse:165.29392                                                  \n",
      "[36]\tvalidation-rmse:165.29392                                                  \n",
      "[37]\tvalidation-rmse:165.29392                                                  \n",
      "[38]\tvalidation-rmse:165.29392                                                  \n",
      "[39]\tvalidation-rmse:165.29392                                                  \n",
      "[40]\tvalidation-rmse:165.29392                                                  \n",
      "[41]\tvalidation-rmse:165.29392                                                  \n",
      "[42]\tvalidation-rmse:165.29392                                                  \n",
      "[43]\tvalidation-rmse:165.29392                                                  \n",
      "[44]\tvalidation-rmse:165.29392                                                  \n",
      "[45]\tvalidation-rmse:165.29392                                                  \n",
      "[46]\tvalidation-rmse:165.29392                                                  \n",
      "[47]\tvalidation-rmse:165.29392                                                  \n",
      "[48]\tvalidation-rmse:165.29392                                                  \n",
      "[49]\tvalidation-rmse:165.29392                                                  \n",
      "[50]\tvalidation-rmse:165.29392                                                  \n",
      "[51]\tvalidation-rmse:165.29392                                                  \n",
      "[52]\tvalidation-rmse:165.29392                                                  \n",
      "[53]\tvalidation-rmse:165.29392                                                  \n",
      "[54]\tvalidation-rmse:165.29392                                                  \n",
      "[55]\tvalidation-rmse:165.29392                                                  \n",
      "[56]\tvalidation-rmse:165.29392                                                  \n",
      "[57]\tvalidation-rmse:165.29392                                                  \n",
      "[58]\tvalidation-rmse:165.29392                                                  \n",
      "[59]\tvalidation-rmse:165.29392                                                  \n",
      "[60]\tvalidation-rmse:165.29392                                                  \n",
      "[61]\tvalidation-rmse:165.29392                                                  \n",
      "[62]\tvalidation-rmse:165.29392                                                  \n",
      "[63]\tvalidation-rmse:165.29392                                                  \n",
      "[16:59:19] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\objective\\regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation-rmse:165.35016                                                   \n",
      "[1]\tvalidation-rmse:165.30153                                                   \n",
      "[2]\tvalidation-rmse:165.29589                                                   \n",
      "[3]\tvalidation-rmse:165.29520                                                   \n",
      "[4]\tvalidation-rmse:165.29379                                                   \n",
      "[5]\tvalidation-rmse:165.29376                                                   \n",
      "[6]\tvalidation-rmse:165.29379                                                   \n",
      "[7]\tvalidation-rmse:165.29379                                                   \n",
      "[8]\tvalidation-rmse:165.29378                                                   \n",
      "[9]\tvalidation-rmse:165.29367                                                   \n",
      "[10]\tvalidation-rmse:165.29367                                                  \n",
      "[11]\tvalidation-rmse:165.29367                                                  \n",
      "[12]\tvalidation-rmse:165.29367                                                  \n",
      "[13]\tvalidation-rmse:165.29367                                                  \n",
      "  6%|â–Œ         | 3/50 [00:07<01:52,  2.38s/trial, best loss: 165.29391738994212]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m search_space \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: scope\u001b[38;5;241m.\u001b[39mint(hp\u001b[38;5;241m.\u001b[39mquniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1\u001b[39m)),\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: hp\u001b[38;5;241m.\u001b[39mloguniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m42\u001b[39m\n\u001b[0;32m      9\u001b[0m }\n\u001b[1;32m---> 11\u001b[0m best_result \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrials\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\AIDOO K. ENOCH\\.conda\\envs\\model_orch\\Lib\\site-packages\\hyperopt\\fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    537\u001b[0m     fn \u001b[38;5;241m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[1;32mc:\\Users\\AIDOO K. ENOCH\\.conda\\envs\\model_orch\\Lib\\site-packages\\hyperopt\\base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[1;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\AIDOO K. ENOCH\\.conda\\envs\\model_orch\\Lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\AIDOO K. ENOCH\\.conda\\envs\\model_orch\\Lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\AIDOO K. ENOCH\\.conda\\envs\\model_orch\\Lib\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\AIDOO K. ENOCH\\.conda\\envs\\model_orch\\Lib\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[1;32mc:\\Users\\AIDOO K. ENOCH\\.conda\\envs\\model_orch\\Lib\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m      3\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mset_tag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxgboost\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_params(params)\n\u001b[1;32m----> 5\u001b[0m booster \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\n\u001b[0;32m     11\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m booster\u001b[38;5;241m.\u001b[39mpredict(valid)\n\u001b[0;32m     13\u001b[0m rmse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_pred, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\AIDOO K. ENOCH\\.conda\\envs\\model_orch\\Lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\AIDOO K. ENOCH\\.conda\\envs\\model_orch\\Lib\\site-packages\\xgboost\\training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\AIDOO K. ENOCH\\.conda\\envs\\model_orch\\Lib\\site-packages\\xgboost\\core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1918\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1919\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1922\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "    'objective': 'reg:linear',\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=Trials()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b8210d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
